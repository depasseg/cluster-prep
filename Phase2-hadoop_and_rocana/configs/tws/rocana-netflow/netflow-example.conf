{
  netflow: {
    udp: {
      // address - The listen address of the netflow receiver
      //   Defaults to '0.0.0.0'
      // address: "0.0.0.0"

      // port - The port used by the netflow receiver
      //   Defaults to 2055
      // port: 2055
    }
  }

  kafka: {
    // brokers - Comma separated list of Kafka broker hosts where events should be published.
    //   This is a required setting, and if it is missing or invalid the netflow receiver will fail
    //   to start.
    // brokers: "kafkahost01.mydomain.com:9092,kafkahost02.mydomain.com:9092"

    batching: {
      // batch-size - The number of records to hold on to before performing a transmission to Kafka.
      //   Increasing this number will improve throughput as aproximately one RPC call to
      //   Kafka is performed per batch.  Note that increased batch size also risks an
      //   increased volume of data loss in the event of an unclean shutdown.
      //   Defaults to '500'.
      // batch-size: 500

      // timeout-ms - The number of milliseconds after the last batch flush when we should perform
      //   another flush even if we have not read 'BatchSize' number of records.
      //   Defaults to 1000 milliseconds.
      // timeout-ms: 1000

    }

    // events-topic - The name of the Kafka topic to which Events will be written.
    //   Defaults to 'events'.
    // events-topic: "events"

    // client-id - A user-specified string sent to Kafka with each request to help trace calls.
    //   This is an advanced configuration option that should only need to be changed
    //   to aid in debugging.
    // client-id: "rocana-netflow"

    // number-workers - The number of workers launched to transmit message batches to Kafka. This
    //   translates to the maximum number of batches that can be in flight at any given point in time.
    //   Note that this only affects non-durable messages such as Syslog data. Replay-able data sources
    //   such as tailed file have their own batching settings.
    //   Defaults to '50'
    // number-workers: 50

    // partitioner - Method for partitioning messages amongst sub-topics. Defaults to 'Random'.
    //   Accepted Values:
    //     Random - Chooses a random partition each time.
    //     RoundRobin - Walks through the available partitions one at a time.
    //     Hash - If the key is nil, or fails to encode, then a random partition is
    //       chosen. Otherwise the FNV-1a hash of the encoded bytes is used modulus the
    //       number of partitions. This ensures that messages with the same key always
    //       end up on the same partition.
    // partitioner: "Random"

    // required-acks - The level of acknowledgement you wish to receive before the message is to be
    //   considered delivered. There is a performance/reliability trade-off inherent in
    //   choosing a value for this setting.  Defaults to 'WaitForLocal'.
    //   Accepted Values:
    //     NoResponse - The producer never waits for an acknowledgement from the broker.
    //       This option provides the lowest latency but the weakest durability
    //       guarantees (some data will be lost when a server fails).
    //     WaitForLocal - The producer gets an acknowledgement after the leader replica
    //       has received the data. This option provides better durability as the client
    //       waits until the server acknowledges the request as successful (only
    //       messages that were written to the now-dead leader but not yet replicated
    //       will be lost).
    //     WaitForAll - The producer gets an acknowledgement after all in-sync replicas
    //       have received the data. This option provides the best durability, we
    //       guarantee that no messages will be lost as long as at least one in sync
    //       replica remains.
    // required-acks: "WaitForLocal"

    retries: {
      // number-retries - The number of attempts to make for any given message to be successfully sent
      //   to Kafka.  After this many attempts the message will be discarded and a warning
      //   will be issued. The exception to this is messages sourced from durable data
      //   sources (eg - tailing/spooling). These messages will be retried until either
      //   they are either successfully or the netflow receiver is shutdown. Defaults to '4'.
      // number-retries: 4

      // wait-ms - The number of milliseconds to wait before retrying to send messages to Kafka
      //   after they have failed to send on their first attempt.  For any subsequent
      //   attempts, the amount of time we wait will grow exponentially.
      //   Defaults to 250 milliseconds.
      // wait-ms: 250

    }
  }

  logging: {
    file: {
      // enabled - Whether or not to log to disk
      //   Defaults to 'true'
      // enabled: true

      // level - The level of log messages written to disk. Messages below the specified level will be
      //   filtered. In order of highest to lowest priority: ERROR, WARN, INFO, DEBUG, or TRACE.
      //   Defaults to 'INFO'.
      // level: "INFO"

      // name - The filename to write log messages. Supports environment variable expansion.
      //   Defaults to "${ROCANA_HOME}/logs/rocana-netflow.log"
      // name: "${ROCANA_HOME}/logs/rocana-netflow.log"
    }
  }

  // The 'primary-field-defaults' section allows configuration of the values for
  // important top level attributes in Events generated by the Netflow Receiver. These include
  // the Location, Host, and Service fields. Note that these defaults can be optionally
  // overridden for each data source to handle ingestion of data multiple services
  // running on the same machine. Additionally, data sources have the ability to be
  // configured to extract these values from the individual messages they process.
  primary-field-defaults: {
    // host - The host on which this netflow receiver runs. If no value is specified
    //   for this setting, it will default to the hostname according to the OS.
    // host: "host02.mydomain.com"

    // location - The location name where this netflow receiver runs. Typically, this is a data center,
    //   region, or other similar designation. You are free to encode hierarchical
    //   information in this value by separating components with slashes. Defaults to
    //   an empty string.
    //   Example: nyc-1/zone-2/rack-12
    // location: ""

    // service - The name of the service producing event data. Like 'host', this will be
    //   automatically discovered in most cases. When receiving events via syslog, the
    //   service will be taken from the service field of the syslog message.
    //   Example: rocana-netflow
    // service: ""

  }

  internal-metrics: {
    http-endpoint: {
      // enabled - Enabling http causes the netflow receiver to launch an http server which responds with a
      //   json struct describing key netflow metrics. Defaults to true.
      // enabled: true

      // address - Address the http metrics server should listen. Defaults to '127.0.0.1'.
      // address: "127.0.0.1"

      // port - Port the http metrics server should be running on. Defaults to '17312'.
      // port: 17312

    }

    logging: {
      // enabled - Whether or not to periodically info log key metrics about the netflow receiver. Defaults to true.
      // enabled: true

      // frequency-secs - Number of seconds between metrics between each time we write metrics to the
      //   info log. Defaults to 60 seconds.
      // frequency-secs: 60

    }
  }

}
