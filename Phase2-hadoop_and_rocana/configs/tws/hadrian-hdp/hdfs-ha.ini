[hdfs-ha-hdfs-site]
dfs.client.failover.proxy.provider.{{ cluster_name }}=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
dfs.ha.automatic-failover.enabled=true
dfs.ha.fencing.methods=shell(/bin/true)
dfs.ha.namenodes.{{ cluster_name }}=nn1,nn2
dfs.namenode.http-address={{ namenode_host }}:50070
dfs.namenode.http-address.{{ cluster_name }}.nn1={{ namenode_host }}:50070
dfs.namenode.http-address.{{ cluster_name }}.nn2={{ secondary_namenode_host }}:50070
dfs.namenode.https-address={{ namenode_host }}1:50470
dfs.namenode.https-address.{{ cluster_name }}.nn1={{ namenode_host }}:50470
dfs.namenode.https-address.{{ cluster_name }}.nn2={{ secondary_namenode_host }}:50470
dfs.namenode.rpc-address.{{ cluster_name }}.nn1={{ namenode_host }}:8020
dfs.namenode.rpc-address.{{ cluster_name }}.nn2={{ secondary_namenode_host }}:8020
dfs.namenode.shared.edits.dir={{ qjm_shared_edits_dir }}
dfs.nameservices={{ cluster_name }}

[hdfs-ha-core-site]
fs.defaultFS=hdfs://{{ cluster_name }}
ha.zookeeper.quorum={{ zookeeper_quorum }}